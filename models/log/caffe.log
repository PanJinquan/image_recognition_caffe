I0713 18:59:55.473206 25233 caffe.cpp:204] Using GPUs 0
I0713 18:59:55.629964 25233 caffe.cpp:209] GPU 0: GeForce GTX TITAN Z
I0713 18:59:55.940977 25233 solver.cpp:45] Initializing solver from parameters: 
test_iter: 30
test_interval: 200
base_lr: 0.1
display: 50
max_iter: 5000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 1000
snapshot: 900
snapshot_prefix: "models/caffenet/caffenet_train"
solver_mode: GPU
device_id: 0
net: "config/caffenet/train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 1e-06
type: "AdaDelta"
I0713 18:59:55.941180 25233 solver.cpp:102] Creating training net from net file: config/caffenet/train_val.prototxt
I0713 18:59:55.941606 25233 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0713 18:59:55.941633 25233 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0713 18:59:55.941821 25233 net.cpp:51] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "dataset/train_lmdb"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 5
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0713 18:59:55.941951 25233 layer_factory.hpp:77] Creating layer data
I0713 18:59:55.942096 25233 db_lmdb.cpp:35] Opened lmdb dataset/train_lmdb
I0713 18:59:55.942131 25233 net.cpp:84] Creating Layer data
I0713 18:59:55.942142 25233 net.cpp:380] data -> data
I0713 18:59:55.942169 25233 net.cpp:380] data -> label
I0713 18:59:55.943392 25233 data_layer.cpp:45] output data size: 32,3,227,227
I0713 18:59:56.010073 25233 net.cpp:122] Setting up data
I0713 18:59:56.010123 25233 net.cpp:129] Top shape: 32 3 227 227 (4946784)
I0713 18:59:56.010129 25233 net.cpp:129] Top shape: 32 (32)
I0713 18:59:56.010133 25233 net.cpp:137] Memory required for data: 19787264
I0713 18:59:56.010146 25233 layer_factory.hpp:77] Creating layer conv1
I0713 18:59:56.010184 25233 net.cpp:84] Creating Layer conv1
I0713 18:59:56.010192 25233 net.cpp:406] conv1 <- data
I0713 18:59:56.010212 25233 net.cpp:380] conv1 -> conv1
I0713 18:59:56.259964 25233 net.cpp:122] Setting up conv1
I0713 18:59:56.260007 25233 net.cpp:129] Top shape: 32 96 55 55 (9292800)
I0713 18:59:56.260012 25233 net.cpp:137] Memory required for data: 56958464
I0713 18:59:56.260038 25233 layer_factory.hpp:77] Creating layer relu1
I0713 18:59:56.260056 25233 net.cpp:84] Creating Layer relu1
I0713 18:59:56.260061 25233 net.cpp:406] relu1 <- conv1
I0713 18:59:56.260068 25233 net.cpp:367] relu1 -> conv1 (in-place)
I0713 18:59:56.260287 25233 net.cpp:122] Setting up relu1
I0713 18:59:56.260299 25233 net.cpp:129] Top shape: 32 96 55 55 (9292800)
I0713 18:59:56.260304 25233 net.cpp:137] Memory required for data: 94129664
I0713 18:59:56.260308 25233 layer_factory.hpp:77] Creating layer pool1
I0713 18:59:56.260318 25233 net.cpp:84] Creating Layer pool1
I0713 18:59:56.260323 25233 net.cpp:406] pool1 <- conv1
I0713 18:59:56.260329 25233 net.cpp:380] pool1 -> pool1
I0713 18:59:56.260388 25233 net.cpp:122] Setting up pool1
I0713 18:59:56.260397 25233 net.cpp:129] Top shape: 32 96 27 27 (2239488)
I0713 18:59:56.260401 25233 net.cpp:137] Memory required for data: 103087616
I0713 18:59:56.260404 25233 layer_factory.hpp:77] Creating layer norm1
I0713 18:59:56.260421 25233 net.cpp:84] Creating Layer norm1
I0713 18:59:56.260424 25233 net.cpp:406] norm1 <- pool1
I0713 18:59:56.260430 25233 net.cpp:380] norm1 -> norm1
I0713 18:59:56.260967 25233 net.cpp:122] Setting up norm1
I0713 18:59:56.261003 25233 net.cpp:129] Top shape: 32 96 27 27 (2239488)
I0713 18:59:56.261006 25233 net.cpp:137] Memory required for data: 112045568
I0713 18:59:56.261011 25233 layer_factory.hpp:77] Creating layer conv2
I0713 18:59:56.261029 25233 net.cpp:84] Creating Layer conv2
I0713 18:59:56.261035 25233 net.cpp:406] conv2 <- norm1
I0713 18:59:56.261044 25233 net.cpp:380] conv2 -> conv2
I0713 18:59:56.268440 25233 net.cpp:122] Setting up conv2
I0713 18:59:56.268465 25233 net.cpp:129] Top shape: 32 256 27 27 (5971968)
I0713 18:59:56.268471 25233 net.cpp:137] Memory required for data: 135933440
I0713 18:59:56.268481 25233 layer_factory.hpp:77] Creating layer relu2
I0713 18:59:56.268491 25233 net.cpp:84] Creating Layer relu2
I0713 18:59:56.268496 25233 net.cpp:406] relu2 <- conv2
I0713 18:59:56.268501 25233 net.cpp:367] relu2 -> conv2 (in-place)
I0713 18:59:56.268972 25233 net.cpp:122] Setting up relu2
I0713 18:59:56.268988 25233 net.cpp:129] Top shape: 32 256 27 27 (5971968)
I0713 18:59:56.268992 25233 net.cpp:137] Memory required for data: 159821312
I0713 18:59:56.268996 25233 layer_factory.hpp:77] Creating layer pool2
I0713 18:59:56.269004 25233 net.cpp:84] Creating Layer pool2
I0713 18:59:56.269008 25233 net.cpp:406] pool2 <- conv2
I0713 18:59:56.269016 25233 net.cpp:380] pool2 -> pool2
I0713 18:59:56.269065 25233 net.cpp:122] Setting up pool2
I0713 18:59:56.269074 25233 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I0713 18:59:56.269078 25233 net.cpp:137] Memory required for data: 165359104
I0713 18:59:56.269081 25233 layer_factory.hpp:77] Creating layer norm2
I0713 18:59:56.269093 25233 net.cpp:84] Creating Layer norm2
I0713 18:59:56.269098 25233 net.cpp:406] norm2 <- pool2
I0713 18:59:56.269104 25233 net.cpp:380] norm2 -> norm2
I0713 18:59:56.269600 25233 net.cpp:122] Setting up norm2
I0713 18:59:56.269615 25233 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I0713 18:59:56.269619 25233 net.cpp:137] Memory required for data: 170896896
I0713 18:59:56.269623 25233 layer_factory.hpp:77] Creating layer conv3
I0713 18:59:56.269636 25233 net.cpp:84] Creating Layer conv3
I0713 18:59:56.269642 25233 net.cpp:406] conv3 <- norm2
I0713 18:59:56.269651 25233 net.cpp:380] conv3 -> conv3
I0713 18:59:56.282863 25233 net.cpp:122] Setting up conv3
I0713 18:59:56.282881 25233 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I0713 18:59:56.282886 25233 net.cpp:137] Memory required for data: 179203584
I0713 18:59:56.282896 25233 layer_factory.hpp:77] Creating layer relu3
I0713 18:59:56.282907 25233 net.cpp:84] Creating Layer relu3
I0713 18:59:56.282910 25233 net.cpp:406] relu3 <- conv3
I0713 18:59:56.282917 25233 net.cpp:367] relu3 -> conv3 (in-place)
I0713 18:59:56.283398 25233 net.cpp:122] Setting up relu3
I0713 18:59:56.283414 25233 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I0713 18:59:56.283417 25233 net.cpp:137] Memory required for data: 187510272
I0713 18:59:56.283422 25233 layer_factory.hpp:77] Creating layer conv4
I0713 18:59:56.283434 25233 net.cpp:84] Creating Layer conv4
I0713 18:59:56.283438 25233 net.cpp:406] conv4 <- conv3
I0713 18:59:56.283445 25233 net.cpp:380] conv4 -> conv4
I0713 18:59:56.294879 25233 net.cpp:122] Setting up conv4
I0713 18:59:56.294898 25233 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I0713 18:59:56.294903 25233 net.cpp:137] Memory required for data: 195816960
I0713 18:59:56.294910 25233 layer_factory.hpp:77] Creating layer relu4
I0713 18:59:56.294919 25233 net.cpp:84] Creating Layer relu4
I0713 18:59:56.294922 25233 net.cpp:406] relu4 <- conv4
I0713 18:59:56.294929 25233 net.cpp:367] relu4 -> conv4 (in-place)
I0713 18:59:56.295403 25233 net.cpp:122] Setting up relu4
I0713 18:59:56.295420 25233 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I0713 18:59:56.295424 25233 net.cpp:137] Memory required for data: 204123648
I0713 18:59:56.295429 25233 layer_factory.hpp:77] Creating layer conv5
I0713 18:59:56.295439 25233 net.cpp:84] Creating Layer conv5
I0713 18:59:56.295444 25233 net.cpp:406] conv5 <- conv4
I0713 18:59:56.295454 25233 net.cpp:380] conv5 -> conv5
I0713 18:59:56.304435 25233 net.cpp:122] Setting up conv5
I0713 18:59:56.304477 25233 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I0713 18:59:56.304484 25233 net.cpp:137] Memory required for data: 209661440
I0713 18:59:56.304497 25233 layer_factory.hpp:77] Creating layer relu5
I0713 18:59:56.304504 25233 net.cpp:84] Creating Layer relu5
I0713 18:59:56.304508 25233 net.cpp:406] relu5 <- conv5
I0713 18:59:56.304517 25233 net.cpp:367] relu5 -> conv5 (in-place)
I0713 18:59:56.304730 25233 net.cpp:122] Setting up relu5
I0713 18:59:56.304745 25233 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I0713 18:59:56.304749 25233 net.cpp:137] Memory required for data: 215199232
I0713 18:59:56.304752 25233 layer_factory.hpp:77] Creating layer pool5
I0713 18:59:56.304760 25233 net.cpp:84] Creating Layer pool5
I0713 18:59:56.304764 25233 net.cpp:406] pool5 <- conv5
I0713 18:59:56.304770 25233 net.cpp:380] pool5 -> pool5
I0713 18:59:56.304821 25233 net.cpp:122] Setting up pool5
I0713 18:59:56.304831 25233 net.cpp:129] Top shape: 32 256 6 6 (294912)
I0713 18:59:56.304833 25233 net.cpp:137] Memory required for data: 216378880
I0713 18:59:56.304837 25233 layer_factory.hpp:77] Creating layer fc6
I0713 18:59:56.304852 25233 net.cpp:84] Creating Layer fc6
I0713 18:59:56.304857 25233 net.cpp:406] fc6 <- pool5
I0713 18:59:56.304863 25233 net.cpp:380] fc6 -> fc6
I0713 18:59:56.357594 25233 net.cpp:122] Setting up fc6
I0713 18:59:56.357630 25233 net.cpp:129] Top shape: 32 512 (16384)
I0713 18:59:56.357635 25233 net.cpp:137] Memory required for data: 216444416
I0713 18:59:56.357646 25233 layer_factory.hpp:77] Creating layer relu6
I0713 18:59:56.357673 25233 net.cpp:84] Creating Layer relu6
I0713 18:59:56.357678 25233 net.cpp:406] relu6 <- fc6
I0713 18:59:56.357686 25233 net.cpp:367] relu6 -> fc6 (in-place)
I0713 18:59:56.358320 25233 net.cpp:122] Setting up relu6
I0713 18:59:56.358333 25233 net.cpp:129] Top shape: 32 512 (16384)
I0713 18:59:56.358336 25233 net.cpp:137] Memory required for data: 216509952
I0713 18:59:56.358340 25233 layer_factory.hpp:77] Creating layer drop6
I0713 18:59:56.358361 25233 net.cpp:84] Creating Layer drop6
I0713 18:59:56.358364 25233 net.cpp:406] drop6 <- fc6
I0713 18:59:56.358373 25233 net.cpp:367] drop6 -> fc6 (in-place)
I0713 18:59:56.358410 25233 net.cpp:122] Setting up drop6
I0713 18:59:56.358417 25233 net.cpp:129] Top shape: 32 512 (16384)
I0713 18:59:56.358420 25233 net.cpp:137] Memory required for data: 216575488
I0713 18:59:56.358424 25233 layer_factory.hpp:77] Creating layer fc7
I0713 18:59:56.358433 25233 net.cpp:84] Creating Layer fc7
I0713 18:59:56.358436 25233 net.cpp:406] fc7 <- fc6
I0713 18:59:56.358443 25233 net.cpp:380] fc7 -> fc7
I0713 18:59:56.361579 25233 net.cpp:122] Setting up fc7
I0713 18:59:56.361593 25233 net.cpp:129] Top shape: 32 512 (16384)
I0713 18:59:56.361595 25233 net.cpp:137] Memory required for data: 216641024
I0713 18:59:56.361601 25233 layer_factory.hpp:77] Creating layer relu7
I0713 18:59:56.361619 25233 net.cpp:84] Creating Layer relu7
I0713 18:59:56.361623 25233 net.cpp:406] relu7 <- fc7
I0713 18:59:56.361629 25233 net.cpp:367] relu7 -> fc7 (in-place)
I0713 18:59:56.361834 25233 net.cpp:122] Setting up relu7
I0713 18:59:56.361843 25233 net.cpp:129] Top shape: 32 512 (16384)
I0713 18:59:56.361846 25233 net.cpp:137] Memory required for data: 216706560
I0713 18:59:56.361850 25233 layer_factory.hpp:77] Creating layer drop7
I0713 18:59:56.361855 25233 net.cpp:84] Creating Layer drop7
I0713 18:59:56.361860 25233 net.cpp:406] drop7 <- fc7
I0713 18:59:56.361868 25233 net.cpp:367] drop7 -> fc7 (in-place)
I0713 18:59:56.361893 25233 net.cpp:122] Setting up drop7
I0713 18:59:56.361901 25233 net.cpp:129] Top shape: 32 512 (16384)
I0713 18:59:56.361904 25233 net.cpp:137] Memory required for data: 216772096
I0713 18:59:56.361907 25233 layer_factory.hpp:77] Creating layer fc8
I0713 18:59:56.361913 25233 net.cpp:84] Creating Layer fc8
I0713 18:59:56.361917 25233 net.cpp:406] fc8 <- fc7
I0713 18:59:56.361923 25233 net.cpp:380] fc8 -> fc8
I0713 18:59:56.362071 25233 net.cpp:122] Setting up fc8
I0713 18:59:56.362078 25233 net.cpp:129] Top shape: 32 5 (160)
I0713 18:59:56.362098 25233 net.cpp:137] Memory required for data: 216772736
I0713 18:59:56.362105 25233 layer_factory.hpp:77] Creating layer loss
I0713 18:59:56.362112 25233 net.cpp:84] Creating Layer loss
I0713 18:59:56.362115 25233 net.cpp:406] loss <- fc8
I0713 18:59:56.362119 25233 net.cpp:406] loss <- label
I0713 18:59:56.362128 25233 net.cpp:380] loss -> loss
I0713 18:59:56.362143 25233 layer_factory.hpp:77] Creating layer loss
I0713 18:59:56.362668 25233 net.cpp:122] Setting up loss
I0713 18:59:56.362680 25233 net.cpp:129] Top shape: (1)
I0713 18:59:56.362684 25233 net.cpp:132]     with loss weight 1
I0713 18:59:56.362711 25233 net.cpp:137] Memory required for data: 216772740
I0713 18:59:56.362715 25233 net.cpp:198] loss needs backward computation.
I0713 18:59:56.362725 25233 net.cpp:198] fc8 needs backward computation.
I0713 18:59:56.362727 25233 net.cpp:198] drop7 needs backward computation.
I0713 18:59:56.362730 25233 net.cpp:198] relu7 needs backward computation.
I0713 18:59:56.362733 25233 net.cpp:198] fc7 needs backward computation.
I0713 18:59:56.362736 25233 net.cpp:198] drop6 needs backward computation.
I0713 18:59:56.362740 25233 net.cpp:198] relu6 needs backward computation.
I0713 18:59:56.362742 25233 net.cpp:198] fc6 needs backward computation.
I0713 18:59:56.362746 25233 net.cpp:198] pool5 needs backward computation.
I0713 18:59:56.362748 25233 net.cpp:198] relu5 needs backward computation.
I0713 18:59:56.362751 25233 net.cpp:198] conv5 needs backward computation.
I0713 18:59:56.362768 25233 net.cpp:198] relu4 needs backward computation.
I0713 18:59:56.362771 25233 net.cpp:198] conv4 needs backward computation.
I0713 18:59:56.362776 25233 net.cpp:198] relu3 needs backward computation.
I0713 18:59:56.362778 25233 net.cpp:198] conv3 needs backward computation.
I0713 18:59:56.362782 25233 net.cpp:198] norm2 needs backward computation.
I0713 18:59:56.362785 25233 net.cpp:198] pool2 needs backward computation.
I0713 18:59:56.362788 25233 net.cpp:198] relu2 needs backward computation.
I0713 18:59:56.362792 25233 net.cpp:198] conv2 needs backward computation.
I0713 18:59:56.362795 25233 net.cpp:198] norm1 needs backward computation.
I0713 18:59:56.362798 25233 net.cpp:198] pool1 needs backward computation.
I0713 18:59:56.362802 25233 net.cpp:198] relu1 needs backward computation.
I0713 18:59:56.362804 25233 net.cpp:198] conv1 needs backward computation.
I0713 18:59:56.362808 25233 net.cpp:200] data does not need backward computation.
I0713 18:59:56.362812 25233 net.cpp:242] This network produces output loss
I0713 18:59:56.362826 25233 net.cpp:255] Network initialization done.
I0713 18:59:56.363142 25233 solver.cpp:190] Creating test net (#0) specified by net file: config/caffenet/train_val.prototxt
I0713 18:59:56.363178 25233 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0713 18:59:56.363343 25233 net.cpp:51] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "dataset/val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 5
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0713 18:59:56.363466 25233 layer_factory.hpp:77] Creating layer data
I0713 18:59:56.363536 25233 db_lmdb.cpp:35] Opened lmdb dataset/val_lmdb
I0713 18:59:56.363556 25233 net.cpp:84] Creating Layer data
I0713 18:59:56.363571 25233 net.cpp:380] data -> data
I0713 18:59:56.363581 25233 net.cpp:380] data -> label
I0713 18:59:56.363903 25233 data_layer.cpp:45] output data size: 50,3,227,227
I0713 18:59:56.450598 25233 net.cpp:122] Setting up data
I0713 18:59:56.450649 25233 net.cpp:129] Top shape: 50 3 227 227 (7729350)
I0713 18:59:56.450654 25233 net.cpp:129] Top shape: 50 (50)
I0713 18:59:56.450659 25233 net.cpp:137] Memory required for data: 30917600
I0713 18:59:56.450668 25233 layer_factory.hpp:77] Creating layer label_data_1_split
I0713 18:59:56.450696 25233 net.cpp:84] Creating Layer label_data_1_split
I0713 18:59:56.450701 25233 net.cpp:406] label_data_1_split <- label
I0713 18:59:56.450711 25233 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0713 18:59:56.450722 25233 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0713 18:59:56.450793 25233 net.cpp:122] Setting up label_data_1_split
I0713 18:59:56.450801 25233 net.cpp:129] Top shape: 50 (50)
I0713 18:59:56.450805 25233 net.cpp:129] Top shape: 50 (50)
I0713 18:59:56.450808 25233 net.cpp:137] Memory required for data: 30918000
I0713 18:59:56.450811 25233 layer_factory.hpp:77] Creating layer conv1
I0713 18:59:56.450827 25233 net.cpp:84] Creating Layer conv1
I0713 18:59:56.450830 25233 net.cpp:406] conv1 <- data
I0713 18:59:56.450837 25233 net.cpp:380] conv1 -> conv1
I0713 18:59:56.453018 25233 net.cpp:122] Setting up conv1
I0713 18:59:56.453033 25233 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0713 18:59:56.453037 25233 net.cpp:137] Memory required for data: 88998000
I0713 18:59:56.453049 25233 layer_factory.hpp:77] Creating layer relu1
I0713 18:59:56.453058 25233 net.cpp:84] Creating Layer relu1
I0713 18:59:56.453060 25233 net.cpp:406] relu1 <- conv1
I0713 18:59:56.453066 25233 net.cpp:367] relu1 -> conv1 (in-place)
I0713 18:59:56.460220 25233 net.cpp:122] Setting up relu1
I0713 18:59:56.460247 25233 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I0713 18:59:56.460250 25233 net.cpp:137] Memory required for data: 147078000
I0713 18:59:56.460254 25233 layer_factory.hpp:77] Creating layer pool1
I0713 18:59:56.460263 25233 net.cpp:84] Creating Layer pool1
I0713 18:59:56.460268 25233 net.cpp:406] pool1 <- conv1
I0713 18:59:56.460273 25233 net.cpp:380] pool1 -> pool1
I0713 18:59:56.460333 25233 net.cpp:122] Setting up pool1
I0713 18:59:56.460341 25233 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0713 18:59:56.460345 25233 net.cpp:137] Memory required for data: 161074800
I0713 18:59:56.460347 25233 layer_factory.hpp:77] Creating layer norm1
I0713 18:59:56.460355 25233 net.cpp:84] Creating Layer norm1
I0713 18:59:56.460359 25233 net.cpp:406] norm1 <- pool1
I0713 18:59:56.460372 25233 net.cpp:380] norm1 -> norm1
I0713 18:59:56.460863 25233 net.cpp:122] Setting up norm1
I0713 18:59:56.460889 25233 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I0713 18:59:56.460892 25233 net.cpp:137] Memory required for data: 175071600
I0713 18:59:56.460896 25233 layer_factory.hpp:77] Creating layer conv2
I0713 18:59:56.460906 25233 net.cpp:84] Creating Layer conv2
I0713 18:59:56.460911 25233 net.cpp:406] conv2 <- norm1
I0713 18:59:56.460916 25233 net.cpp:380] conv2 -> conv2
I0713 18:59:56.466302 25233 net.cpp:122] Setting up conv2
I0713 18:59:56.466329 25233 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0713 18:59:56.466333 25233 net.cpp:137] Memory required for data: 212396400
I0713 18:59:56.466342 25233 layer_factory.hpp:77] Creating layer relu2
I0713 18:59:56.466348 25233 net.cpp:84] Creating Layer relu2
I0713 18:59:56.466351 25233 net.cpp:406] relu2 <- conv2
I0713 18:59:56.466358 25233 net.cpp:367] relu2 -> conv2 (in-place)
I0713 18:59:56.466800 25233 net.cpp:122] Setting up relu2
I0713 18:59:56.466812 25233 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I0713 18:59:56.466826 25233 net.cpp:137] Memory required for data: 249721200
I0713 18:59:56.466830 25233 layer_factory.hpp:77] Creating layer pool2
I0713 18:59:56.466840 25233 net.cpp:84] Creating Layer pool2
I0713 18:59:56.466845 25233 net.cpp:406] pool2 <- conv2
I0713 18:59:56.466850 25233 net.cpp:380] pool2 -> pool2
I0713 18:59:56.466928 25233 net.cpp:122] Setting up pool2
I0713 18:59:56.466936 25233 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0713 18:59:56.466939 25233 net.cpp:137] Memory required for data: 258374000
I0713 18:59:56.466943 25233 layer_factory.hpp:77] Creating layer norm2
I0713 18:59:56.466948 25233 net.cpp:84] Creating Layer norm2
I0713 18:59:56.466951 25233 net.cpp:406] norm2 <- pool2
I0713 18:59:56.466958 25233 net.cpp:380] norm2 -> norm2
I0713 18:59:56.467165 25233 net.cpp:122] Setting up norm2
I0713 18:59:56.467175 25233 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0713 18:59:56.467180 25233 net.cpp:137] Memory required for data: 267026800
I0713 18:59:56.467182 25233 layer_factory.hpp:77] Creating layer conv3
I0713 18:59:56.467192 25233 net.cpp:84] Creating Layer conv3
I0713 18:59:56.467195 25233 net.cpp:406] conv3 <- norm2
I0713 18:59:56.467203 25233 net.cpp:380] conv3 -> conv3
I0713 18:59:56.478703 25233 net.cpp:122] Setting up conv3
I0713 18:59:56.478739 25233 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0713 18:59:56.478744 25233 net.cpp:137] Memory required for data: 280006000
I0713 18:59:56.478756 25233 layer_factory.hpp:77] Creating layer relu3
I0713 18:59:56.478766 25233 net.cpp:84] Creating Layer relu3
I0713 18:59:56.478770 25233 net.cpp:406] relu3 <- conv3
I0713 18:59:56.478778 25233 net.cpp:367] relu3 -> conv3 (in-place)
I0713 18:59:56.479215 25233 net.cpp:122] Setting up relu3
I0713 18:59:56.479241 25233 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0713 18:59:56.479245 25233 net.cpp:137] Memory required for data: 292985200
I0713 18:59:56.479249 25233 layer_factory.hpp:77] Creating layer conv4
I0713 18:59:56.479260 25233 net.cpp:84] Creating Layer conv4
I0713 18:59:56.479264 25233 net.cpp:406] conv4 <- conv3
I0713 18:59:56.479270 25233 net.cpp:380] conv4 -> conv4
I0713 18:59:56.488533 25233 net.cpp:122] Setting up conv4
I0713 18:59:56.488561 25233 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0713 18:59:56.488565 25233 net.cpp:137] Memory required for data: 305964400
I0713 18:59:56.488574 25233 layer_factory.hpp:77] Creating layer relu4
I0713 18:59:56.488582 25233 net.cpp:84] Creating Layer relu4
I0713 18:59:56.488587 25233 net.cpp:406] relu4 <- conv4
I0713 18:59:56.488592 25233 net.cpp:367] relu4 -> conv4 (in-place)
I0713 18:59:56.489042 25233 net.cpp:122] Setting up relu4
I0713 18:59:56.489053 25233 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I0713 18:59:56.489068 25233 net.cpp:137] Memory required for data: 318943600
I0713 18:59:56.489071 25233 layer_factory.hpp:77] Creating layer conv5
I0713 18:59:56.489084 25233 net.cpp:84] Creating Layer conv5
I0713 18:59:56.489087 25233 net.cpp:406] conv5 <- conv4
I0713 18:59:56.489095 25233 net.cpp:380] conv5 -> conv5
I0713 18:59:56.496018 25233 net.cpp:122] Setting up conv5
I0713 18:59:56.496037 25233 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0713 18:59:56.496039 25233 net.cpp:137] Memory required for data: 327596400
I0713 18:59:56.496053 25233 layer_factory.hpp:77] Creating layer relu5
I0713 18:59:56.496062 25233 net.cpp:84] Creating Layer relu5
I0713 18:59:56.496064 25233 net.cpp:406] relu5 <- conv5
I0713 18:59:56.496070 25233 net.cpp:367] relu5 -> conv5 (in-place)
I0713 18:59:56.496537 25233 net.cpp:122] Setting up relu5
I0713 18:59:56.496551 25233 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I0713 18:59:56.496556 25233 net.cpp:137] Memory required for data: 336249200
I0713 18:59:56.496570 25233 layer_factory.hpp:77] Creating layer pool5
I0713 18:59:56.496585 25233 net.cpp:84] Creating Layer pool5
I0713 18:59:56.496590 25233 net.cpp:406] pool5 <- conv5
I0713 18:59:56.496596 25233 net.cpp:380] pool5 -> pool5
I0713 18:59:56.496646 25233 net.cpp:122] Setting up pool5
I0713 18:59:56.496654 25233 net.cpp:129] Top shape: 50 256 6 6 (460800)
I0713 18:59:56.496657 25233 net.cpp:137] Memory required for data: 338092400
I0713 18:59:56.496660 25233 layer_factory.hpp:77] Creating layer fc6
I0713 18:59:56.496670 25233 net.cpp:84] Creating Layer fc6
I0713 18:59:56.496673 25233 net.cpp:406] fc6 <- pool5
I0713 18:59:56.496680 25233 net.cpp:380] fc6 -> fc6
I0713 18:59:56.551751 25233 net.cpp:122] Setting up fc6
I0713 18:59:56.551785 25233 net.cpp:129] Top shape: 50 512 (25600)
I0713 18:59:56.551789 25233 net.cpp:137] Memory required for data: 338194800
I0713 18:59:56.551811 25233 layer_factory.hpp:77] Creating layer relu6
I0713 18:59:56.551826 25233 net.cpp:84] Creating Layer relu6
I0713 18:59:56.551831 25233 net.cpp:406] relu6 <- fc6
I0713 18:59:56.551838 25233 net.cpp:367] relu6 -> fc6 (in-place)
I0713 18:59:56.552126 25233 net.cpp:122] Setting up relu6
I0713 18:59:56.552136 25233 net.cpp:129] Top shape: 50 512 (25600)
I0713 18:59:56.552139 25233 net.cpp:137] Memory required for data: 338297200
I0713 18:59:56.552143 25233 layer_factory.hpp:77] Creating layer drop6
I0713 18:59:56.552150 25233 net.cpp:84] Creating Layer drop6
I0713 18:59:56.552155 25233 net.cpp:406] drop6 <- fc6
I0713 18:59:56.552160 25233 net.cpp:367] drop6 -> fc6 (in-place)
I0713 18:59:56.552203 25233 net.cpp:122] Setting up drop6
I0713 18:59:56.552211 25233 net.cpp:129] Top shape: 50 512 (25600)
I0713 18:59:56.552214 25233 net.cpp:137] Memory required for data: 338399600
I0713 18:59:56.552217 25233 layer_factory.hpp:77] Creating layer fc7
I0713 18:59:56.552225 25233 net.cpp:84] Creating Layer fc7
I0713 18:59:56.552228 25233 net.cpp:406] fc7 <- fc6
I0713 18:59:56.552237 25233 net.cpp:380] fc7 -> fc7
I0713 18:59:56.563635 25233 net.cpp:122] Setting up fc7
I0713 18:59:56.563660 25233 net.cpp:129] Top shape: 50 512 (25600)
I0713 18:59:56.563664 25233 net.cpp:137] Memory required for data: 338502000
I0713 18:59:56.563671 25233 layer_factory.hpp:77] Creating layer relu7
I0713 18:59:56.563678 25233 net.cpp:84] Creating Layer relu7
I0713 18:59:56.563681 25233 net.cpp:406] relu7 <- fc7
I0713 18:59:56.563688 25233 net.cpp:367] relu7 -> fc7 (in-place)
I0713 18:59:56.564177 25233 net.cpp:122] Setting up relu7
I0713 18:59:56.564189 25233 net.cpp:129] Top shape: 50 512 (25600)
I0713 18:59:56.564203 25233 net.cpp:137] Memory required for data: 338604400
I0713 18:59:56.564208 25233 layer_factory.hpp:77] Creating layer drop7
I0713 18:59:56.564215 25233 net.cpp:84] Creating Layer drop7
I0713 18:59:56.564220 25233 net.cpp:406] drop7 <- fc7
I0713 18:59:56.564227 25233 net.cpp:367] drop7 -> fc7 (in-place)
I0713 18:59:56.564267 25233 net.cpp:122] Setting up drop7
I0713 18:59:56.564275 25233 net.cpp:129] Top shape: 50 512 (25600)
I0713 18:59:56.564277 25233 net.cpp:137] Memory required for data: 338706800
I0713 18:59:56.564280 25233 layer_factory.hpp:77] Creating layer fc8
I0713 18:59:56.564290 25233 net.cpp:84] Creating Layer fc8
I0713 18:59:56.564292 25233 net.cpp:406] fc8 <- fc7
I0713 18:59:56.564299 25233 net.cpp:380] fc8 -> fc8
I0713 18:59:56.564460 25233 net.cpp:122] Setting up fc8
I0713 18:59:56.564469 25233 net.cpp:129] Top shape: 50 5 (250)
I0713 18:59:56.564472 25233 net.cpp:137] Memory required for data: 338707800
I0713 18:59:56.564478 25233 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0713 18:59:56.564486 25233 net.cpp:84] Creating Layer fc8_fc8_0_split
I0713 18:59:56.564489 25233 net.cpp:406] fc8_fc8_0_split <- fc8
I0713 18:59:56.564496 25233 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0713 18:59:56.564502 25233 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0713 18:59:56.564541 25233 net.cpp:122] Setting up fc8_fc8_0_split
I0713 18:59:56.564548 25233 net.cpp:129] Top shape: 50 5 (250)
I0713 18:59:56.564553 25233 net.cpp:129] Top shape: 50 5 (250)
I0713 18:59:56.564563 25233 net.cpp:137] Memory required for data: 338709800
I0713 18:59:56.564565 25233 layer_factory.hpp:77] Creating layer accuracy
I0713 18:59:56.564574 25233 net.cpp:84] Creating Layer accuracy
I0713 18:59:56.564577 25233 net.cpp:406] accuracy <- fc8_fc8_0_split_0
I0713 18:59:56.564581 25233 net.cpp:406] accuracy <- label_data_1_split_0
I0713 18:59:56.564590 25233 net.cpp:380] accuracy -> accuracy
I0713 18:59:56.564599 25233 net.cpp:122] Setting up accuracy
I0713 18:59:56.564602 25233 net.cpp:129] Top shape: (1)
I0713 18:59:56.564604 25233 net.cpp:137] Memory required for data: 338709804
I0713 18:59:56.564608 25233 layer_factory.hpp:77] Creating layer loss
I0713 18:59:56.564631 25233 net.cpp:84] Creating Layer loss
I0713 18:59:56.564635 25233 net.cpp:406] loss <- fc8_fc8_0_split_1
I0713 18:59:56.564640 25233 net.cpp:406] loss <- label_data_1_split_1
I0713 18:59:56.564646 25233 net.cpp:380] loss -> loss
I0713 18:59:56.564653 25233 layer_factory.hpp:77] Creating layer loss
I0713 18:59:56.565194 25233 net.cpp:122] Setting up loss
I0713 18:59:56.565219 25233 net.cpp:129] Top shape: (1)
I0713 18:59:56.565222 25233 net.cpp:132]     with loss weight 1
I0713 18:59:56.565234 25233 net.cpp:137] Memory required for data: 338709808
I0713 18:59:56.565238 25233 net.cpp:198] loss needs backward computation.
I0713 18:59:56.565243 25233 net.cpp:200] accuracy does not need backward computation.
I0713 18:59:56.565248 25233 net.cpp:198] fc8_fc8_0_split needs backward computation.
I0713 18:59:56.565250 25233 net.cpp:198] fc8 needs backward computation.
I0713 18:59:56.565253 25233 net.cpp:198] drop7 needs backward computation.
I0713 18:59:56.565256 25233 net.cpp:198] relu7 needs backward computation.
I0713 18:59:56.565259 25233 net.cpp:198] fc7 needs backward computation.
I0713 18:59:56.565263 25233 net.cpp:198] drop6 needs backward computation.
I0713 18:59:56.565265 25233 net.cpp:198] relu6 needs backward computation.
I0713 18:59:56.565268 25233 net.cpp:198] fc6 needs backward computation.
I0713 18:59:56.565270 25233 net.cpp:198] pool5 needs backward computation.
I0713 18:59:56.565274 25233 net.cpp:198] relu5 needs backward computation.
I0713 18:59:56.565277 25233 net.cpp:198] conv5 needs backward computation.
I0713 18:59:56.565280 25233 net.cpp:198] relu4 needs backward computation.
I0713 18:59:56.565284 25233 net.cpp:198] conv4 needs backward computation.
I0713 18:59:56.565286 25233 net.cpp:198] relu3 needs backward computation.
I0713 18:59:56.565289 25233 net.cpp:198] conv3 needs backward computation.
I0713 18:59:56.565294 25233 net.cpp:198] norm2 needs backward computation.
I0713 18:59:56.565296 25233 net.cpp:198] pool2 needs backward computation.
I0713 18:59:56.565299 25233 net.cpp:198] relu2 needs backward computation.
I0713 18:59:56.565302 25233 net.cpp:198] conv2 needs backward computation.
I0713 18:59:56.565305 25233 net.cpp:198] norm1 needs backward computation.
I0713 18:59:56.565310 25233 net.cpp:198] pool1 needs backward computation.
I0713 18:59:56.565312 25233 net.cpp:198] relu1 needs backward computation.
I0713 18:59:56.565315 25233 net.cpp:198] conv1 needs backward computation.
I0713 18:59:56.565318 25233 net.cpp:200] label_data_1_split does not need backward computation.
I0713 18:59:56.565322 25233 net.cpp:200] data does not need backward computation.
I0713 18:59:56.565325 25233 net.cpp:242] This network produces output accuracy
I0713 18:59:56.565328 25233 net.cpp:242] This network produces output loss
I0713 18:59:56.565353 25233 net.cpp:255] Network initialization done.
I0713 18:59:56.565440 25233 solver.cpp:57] Solver scaffolding done.
I0713 18:59:56.566228 25233 caffe.cpp:239] Starting Optimization
I0713 18:59:56.566236 25233 solver.cpp:289] Solving CaffeNet
I0713 18:59:56.566249 25233 solver.cpp:290] Learning Rate Policy: step
I0713 18:59:56.568481 25233 solver.cpp:347] Iteration 0, Testing net (#0)
I0713 18:59:57.216766 25233 blocking_queue.cpp:49] Waiting for data
I0713 18:59:58.495959 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 18:59:58.582007 25233 solver.cpp:414]     Test net output #0: accuracy = 0
I0713 18:59:58.582077 25233 solver.cpp:414]     Test net output #1: loss = 1.56209 (* 1 = 1.56209 loss)
I0713 18:59:58.713145 25233 solver.cpp:239] Iteration 0 (0 iter/s, 2.14681s/50 iters), loss = 1.60011
I0713 18:59:58.713260 25233 solver.cpp:258]     Train net output #0: loss = 1.60011 (* 1 = 1.60011 loss)
I0713 18:59:58.713335 25233 sgd_solver.cpp:112] Iteration 0, lr = 0.1
I0713 19:00:03.874585 25233 solver.cpp:239] Iteration 50 (9.68732 iter/s, 5.16138s/50 iters), loss = 0.000170825
I0713 19:00:03.874693 25233 solver.cpp:258]     Train net output #0: loss = 0.000170773 (* 1 = 0.000170773 loss)
I0713 19:00:03.874750 25233 sgd_solver.cpp:112] Iteration 50, lr = 0.1
I0713 19:00:06.420449 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:00:09.040375 25233 solver.cpp:239] Iteration 100 (9.67921 iter/s, 5.16571s/50 iters), loss = 5.34092e-05
I0713 19:00:09.040496 25233 solver.cpp:258]     Train net output #0: loss = 5.3357e-05 (* 1 = 5.3357e-05 loss)
I0713 19:00:09.040513 25233 sgd_solver.cpp:112] Iteration 100, lr = 0.1
I0713 19:00:14.200543 25233 solver.cpp:239] Iteration 150 (9.68982 iter/s, 5.16006s/50 iters), loss = 1.55034e-05
I0713 19:00:14.200637 25233 solver.cpp:258]     Train net output #0: loss = 1.54512e-05 (* 1 = 1.54512e-05 loss)
I0713 19:00:14.200651 25233 sgd_solver.cpp:112] Iteration 150, lr = 0.1
I0713 19:00:14.495961 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:00:19.259956 25233 solver.cpp:347] Iteration 200, Testing net (#0)
I0713 19:00:21.131845 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:00:21.191298 25233 solver.cpp:414]     Test net output #0: accuracy = 1
I0713 19:00:21.191355 25233 solver.cpp:414]     Test net output #1: loss = 5.91306e-06 (* 1 = 5.91306e-06 loss)
I0713 19:00:21.304680 25233 solver.cpp:239] Iteration 200 (7.03818 iter/s, 7.10411s/50 iters), loss = 1.43501e-05
I0713 19:00:21.312322 25233 solver.cpp:258]     Train net output #0: loss = 1.42979e-05 (* 1 = 1.42979e-05 loss)
I0713 19:00:21.312348 25233 sgd_solver.cpp:112] Iteration 200, lr = 0.1
I0713 19:00:24.492669 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:00:26.510932 25233 solver.cpp:239] Iteration 250 (9.61789 iter/s, 5.19864s/50 iters), loss = 1.12655e-05
I0713 19:00:26.511307 25233 solver.cpp:258]     Train net output #0: loss = 1.12134e-05 (* 1 = 1.12134e-05 loss)
I0713 19:00:26.511323 25233 sgd_solver.cpp:112] Iteration 250, lr = 0.1
I0713 19:00:31.660158 25233 solver.cpp:239] Iteration 300 (9.71086 iter/s, 5.14888s/50 iters), loss = 7.98715e-06
I0713 19:00:31.660224 25233 solver.cpp:258]     Train net output #0: loss = 7.93498e-06 (* 1 = 7.93498e-06 loss)
I0713 19:00:31.660234 25233 sgd_solver.cpp:112] Iteration 300, lr = 0.1
I0713 19:00:32.580142 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:00:37.437978 25233 solver.cpp:239] Iteration 350 (8.65382 iter/s, 5.77779s/50 iters), loss = 8.10264e-06
I0713 19:00:37.438076 25233 solver.cpp:258]     Train net output #0: loss = 8.05047e-06 (* 1 = 8.05047e-06 loss)
I0713 19:00:37.438089 25233 sgd_solver.cpp:112] Iteration 350, lr = 0.1
I0713 19:00:42.053679 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:00:43.536183 25233 solver.cpp:347] Iteration 400, Testing net (#0)
I0713 19:00:45.613167 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:00:45.698473 25233 solver.cpp:414]     Test net output #0: accuracy = 1
I0713 19:00:45.698549 25233 solver.cpp:414]     Test net output #1: loss = 2.5855e-06 (* 1 = 2.5855e-06 loss)
I0713 19:00:45.840250 25233 solver.cpp:239] Iteration 400 (5.95082 iter/s, 8.4022s/50 iters), loss = 5.33097e-06
I0713 19:00:45.840368 25233 solver.cpp:258]     Train net output #0: loss = 5.2788e-06 (* 1 = 5.2788e-06 loss)
I0713 19:00:45.840394 25233 sgd_solver.cpp:112] Iteration 400, lr = 0.1
I0713 19:00:52.210593 25233 solver.cpp:239] Iteration 450 (7.84892 iter/s, 6.3703s/50 iters), loss = 2.56675e-06
I0713 19:00:52.210661 25233 solver.cpp:258]     Train net output #0: loss = 2.51458e-06 (* 1 = 2.51458e-06 loss)
I0713 19:00:52.210675 25233 sgd_solver.cpp:112] Iteration 450, lr = 0.1
I0713 19:00:54.057638 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:00:58.764937 25233 solver.cpp:239] Iteration 500 (7.62866 iter/s, 6.55423s/50 iters), loss = 6.92544e-06
I0713 19:00:58.765228 25233 solver.cpp:258]     Train net output #0: loss = 6.87327e-06 (* 1 = 6.87327e-06 loss)
I0713 19:00:58.765262 25233 sgd_solver.cpp:112] Iteration 500, lr = 0.1
I0713 19:01:04.156028 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:01:05.091071 25233 solver.cpp:239] Iteration 550 (7.90404 iter/s, 6.32588s/50 iters), loss = 7.47683e-06
I0713 19:01:05.091173 25233 solver.cpp:258]     Train net output #0: loss = 7.42466e-06 (* 1 = 7.42466e-06 loss)
I0713 19:01:05.091192 25233 sgd_solver.cpp:112] Iteration 550, lr = 0.1
I0713 19:01:11.213985 25233 solver.cpp:347] Iteration 600, Testing net (#0)
I0713 19:01:13.256561 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:01:13.337721 25233 solver.cpp:414]     Test net output #0: accuracy = 1
I0713 19:01:13.337790 25233 solver.cpp:414]     Test net output #1: loss = 1.92365e-06 (* 1 = 1.92365e-06 loss)
I0713 19:01:13.468958 25233 solver.cpp:239] Iteration 600 (5.96814 iter/s, 8.37782s/50 iters), loss = 2.38794e-06
I0713 19:01:13.469074 25233 solver.cpp:258]     Train net output #0: loss = 2.33577e-06 (* 1 = 2.33577e-06 loss)
I0713 19:01:13.469101 25233 sgd_solver.cpp:112] Iteration 600, lr = 0.1
I0713 19:01:16.014187 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:01:19.764014 25233 solver.cpp:239] Iteration 650 (7.94279 iter/s, 6.29502s/50 iters), loss = 3.9712e-06
I0713 19:01:19.764081 25233 solver.cpp:258]     Train net output #0: loss = 3.91904e-06 (* 1 = 3.91904e-06 loss)
I0713 19:01:19.764089 25233 sgd_solver.cpp:112] Iteration 650, lr = 0.1
I0713 19:01:25.899878 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:01:26.097713 25233 solver.cpp:239] Iteration 700 (7.89427 iter/s, 6.33371s/50 iters), loss = 6.65725e-06
I0713 19:01:26.097772 25233 solver.cpp:258]     Train net output #0: loss = 6.60509e-06 (* 1 = 6.60509e-06 loss)
I0713 19:01:26.097780 25233 sgd_solver.cpp:112] Iteration 700, lr = 0.1
I0713 19:01:32.396983 25233 solver.cpp:239] Iteration 750 (7.93744 iter/s, 6.29926s/50 iters), loss = 4.40333e-06
I0713 19:01:32.397271 25233 solver.cpp:258]     Train net output #0: loss = 4.35116e-06 (* 1 = 4.35116e-06 loss)
I0713 19:01:32.397294 25233 sgd_solver.cpp:112] Iteration 750, lr = 0.1
I0713 19:01:35.798529 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:01:38.579195 25233 solver.cpp:347] Iteration 800, Testing net (#0)
I0713 19:01:40.690455 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:01:40.774338 25233 solver.cpp:414]     Test net output #0: accuracy = 1
I0713 19:01:40.774436 25233 solver.cpp:414]     Test net output #1: loss = 1.67632e-06 (* 1 = 1.67632e-06 loss)
I0713 19:01:40.905624 25233 solver.cpp:239] Iteration 800 (5.8765 iter/s, 8.50846s/50 iters), loss = 5.09252e-06
I0713 19:01:40.905689 25233 solver.cpp:258]     Train net output #0: loss = 5.04036e-06 (* 1 = 5.04036e-06 loss)
I0713 19:01:40.905700 25233 sgd_solver.cpp:112] Iteration 800, lr = 0.1
I0713 19:01:47.251456 25233 solver.cpp:239] Iteration 850 (7.87921 iter/s, 6.34581s/50 iters), loss = 4.67903e-06
I0713 19:01:47.251557 25233 solver.cpp:258]     Train net output #0: loss = 4.62686e-06 (* 1 = 4.62686e-06 loss)
I0713 19:01:47.251575 25233 sgd_solver.cpp:112] Iteration 850, lr = 0.1
I0713 19:01:47.841692 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:01:53.368099 25233 solver.cpp:464] Snapshotting to binary proto file models/caffenet/caffenet_train_iter_900.caffemodel
I0713 19:01:53.678710 25233 sgd_solver.cpp:284] Snapshotting solver state to binary proto file models/caffenet/caffenet_train_iter_900.solverstate
I0713 19:01:53.926223 25233 solver.cpp:239] Iteration 900 (7.49092 iter/s, 6.67475s/50 iters), loss = 2.77164e-06
I0713 19:01:53.926283 25233 solver.cpp:258]     Train net output #0: loss = 2.71948e-06 (* 1 = 2.71948e-06 loss)
I0713 19:01:53.926297 25233 sgd_solver.cpp:112] Iteration 900, lr = 0.1
I0713 19:01:58.098165 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:02:00.221177 25233 solver.cpp:239] Iteration 950 (7.94286 iter/s, 6.29496s/50 iters), loss = 6.06857e-06
I0713 19:02:00.226135 25233 solver.cpp:258]     Train net output #0: loss = 6.01641e-06 (* 1 = 6.01641e-06 loss)
I0713 19:02:00.226152 25233 sgd_solver.cpp:112] Iteration 950, lr = 0.1
I0713 19:02:06.361523 25233 solver.cpp:347] Iteration 1000, Testing net (#0)
I0713 19:02:08.368230 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:02:08.457307 25233 solver.cpp:414]     Test net output #0: accuracy = 1
I0713 19:02:08.457384 25233 solver.cpp:414]     Test net output #1: loss = 1.5471e-06 (* 1 = 1.5471e-06 loss)
I0713 19:02:08.579870 25233 solver.cpp:239] Iteration 1000 (5.98528 iter/s, 8.35383s/50 iters), loss = 6.9182e-06
I0713 19:02:08.586796 25233 solver.cpp:258]     Train net output #0: loss = 6.86604e-06 (* 1 = 6.86604e-06 loss)
I0713 19:02:08.586832 25233 sgd_solver.cpp:112] Iteration 1000, lr = 0.01
I0713 19:02:09.956640 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:02:14.851358 25233 solver.cpp:239] Iteration 1050 (7.9813 iter/s, 6.26464s/50 iters), loss = 3.38633e-06
I0713 19:02:14.857489 25233 solver.cpp:258]     Train net output #0: loss = 3.33416e-06 (* 1 = 3.33416e-06 loss)
I0713 19:02:14.857520 25233 sgd_solver.cpp:112] Iteration 1050, lr = 0.01
I0713 19:02:19.815405 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:02:21.287528 25233 solver.cpp:239] Iteration 1100 (7.7759 iter/s, 6.43012s/50 iters), loss = 4.15748e-06
I0713 19:02:21.287603 25233 solver.cpp:258]     Train net output #0: loss = 4.10532e-06 (* 1 = 4.10532e-06 loss)
I0713 19:02:21.287616 25233 sgd_solver.cpp:112] Iteration 1100, lr = 0.01
I0713 19:02:27.933863 25233 solver.cpp:239] Iteration 1150 (7.52297 iter/s, 6.64631s/50 iters), loss = 1.06866e-05
I0713 19:02:27.933972 25233 solver.cpp:258]     Train net output #0: loss = 1.06344e-05 (* 1 = 1.06344e-05 loss)
I0713 19:02:27.933992 25233 sgd_solver.cpp:112] Iteration 1150, lr = 0.01
I0713 19:02:30.069242 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:02:34.172253 25233 solver.cpp:347] Iteration 1200, Testing net (#0)
I0713 19:02:36.243468 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:02:36.325976 25233 solver.cpp:414]     Test net output #0: accuracy = 1
I0713 19:02:36.326040 25233 solver.cpp:414]     Test net output #1: loss = 1.54289e-06 (* 1 = 1.54289e-06 loss)
I0713 19:02:36.467685 25233 solver.cpp:239] Iteration 1200 (5.85904 iter/s, 8.53382s/50 iters), loss = 6.08362e-06
I0713 19:02:36.467923 25233 solver.cpp:258]     Train net output #0: loss = 6.03145e-06 (* 1 = 6.03145e-06 loss)
I0713 19:02:36.467945 25233 sgd_solver.cpp:112] Iteration 1200, lr = 0.01
I0713 19:02:42.304435 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:02:42.844563 25233 solver.cpp:239] Iteration 1250 (7.84102 iter/s, 6.37672s/50 iters), loss = 1.93344e-06
I0713 19:02:42.851965 25233 solver.cpp:258]     Train net output #0: loss = 1.88128e-06 (* 1 = 1.88128e-06 loss)
I0713 19:02:42.851987 25233 sgd_solver.cpp:112] Iteration 1250, lr = 0.01
I0713 19:02:49.268884 25233 solver.cpp:239] Iteration 1300 (7.7918 iter/s, 6.41701s/50 iters), loss = 2.68596e-06
I0713 19:02:49.268970 25233 solver.cpp:258]     Train net output #0: loss = 2.63379e-06 (* 1 = 2.63379e-06 loss)
I0713 19:02:49.268986 25233 sgd_solver.cpp:112] Iteration 1300, lr = 0.01
I0713 19:02:52.137802 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:02:55.743103 25233 solver.cpp:239] Iteration 1350 (7.72294 iter/s, 6.47422s/50 iters), loss = 4.15001e-06
I0713 19:02:55.743162 25233 solver.cpp:258]     Train net output #0: loss = 4.09784e-06 (* 1 = 4.09784e-06 loss)
I0713 19:02:55.743172 25233 sgd_solver.cpp:112] Iteration 1350, lr = 0.01
I0713 19:03:02.035267 25233 solver.cpp:347] Iteration 1400, Testing net (#0)
I0713 19:03:04.072355 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:03:04.179563 25233 solver.cpp:414]     Test net output #0: accuracy = 1
I0713 19:03:04.179615 25233 solver.cpp:414]     Test net output #1: loss = 1.54503e-06 (* 1 = 1.54503e-06 loss)
I0713 19:03:04.320803 25233 solver.cpp:239] Iteration 1400 (5.82903 iter/s, 8.57776s/50 iters), loss = 1.56092e-06
I0713 19:03:04.320875 25233 solver.cpp:258]     Train net output #0: loss = 1.50876e-06 (* 1 = 1.50876e-06 loss)
I0713 19:03:04.320890 25233 sgd_solver.cpp:112] Iteration 1400, lr = 0.01
I0713 19:03:04.381719 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:03:10.713162 25233 solver.cpp:239] Iteration 1450 (7.82184 iter/s, 6.39236s/50 iters), loss = 2.54813e-06
I0713 19:03:10.713454 25233 solver.cpp:258]     Train net output #0: loss = 2.49596e-06 (* 1 = 2.49596e-06 loss)
I0713 19:03:10.713485 25233 sgd_solver.cpp:112] Iteration 1450, lr = 0.01
I0713 19:03:14.386138 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:03:16.959762 25233 solver.cpp:239] Iteration 1500 (8.00465 iter/s, 6.24637s/50 iters), loss = 8.09528e-06
I0713 19:03:16.965507 25233 solver.cpp:258]     Train net output #0: loss = 8.04312e-06 (* 1 = 8.04312e-06 loss)
I0713 19:03:16.965536 25233 sgd_solver.cpp:112] Iteration 1500, lr = 0.01
I0713 19:03:23.240077 25233 solver.cpp:239] Iteration 1550 (7.96859 iter/s, 6.27464s/50 iters), loss = 4.64929e-06
I0713 19:03:23.240183 25233 solver.cpp:258]     Train net output #0: loss = 4.59713e-06 (* 1 = 4.59713e-06 loss)
I0713 19:03:23.240201 25233 sgd_solver.cpp:112] Iteration 1550, lr = 0.01
I0713 19:03:24.024188 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:03:29.209290 25233 solver.cpp:347] Iteration 1600, Testing net (#0)
I0713 19:03:31.200675 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:03:31.267926 25233 solver.cpp:414]     Test net output #0: accuracy = 1
I0713 19:03:31.267997 25233 solver.cpp:414]     Test net output #1: loss = 1.54623e-06 (* 1 = 1.54623e-06 loss)
I0713 19:03:31.399513 25233 solver.cpp:239] Iteration 1600 (6.12786 iter/s, 8.15945s/50 iters), loss = 2.37676e-06
I0713 19:03:31.405791 25233 solver.cpp:258]     Train net output #0: loss = 2.32459e-06 (* 1 = 2.32459e-06 loss)
I0713 19:03:31.405814 25233 sgd_solver.cpp:112] Iteration 1600, lr = 0.01
I0713 19:03:35.814486 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:03:37.749639 25233 solver.cpp:239] Iteration 1650 (7.88156 iter/s, 6.34392s/50 iters), loss = 2.74184e-06
I0713 19:03:37.749716 25233 solver.cpp:258]     Train net output #0: loss = 2.68967e-06 (* 1 = 2.68967e-06 loss)
I0713 19:03:37.749732 25233 sgd_solver.cpp:112] Iteration 1650, lr = 0.01
I0713 19:03:44.093890 25233 solver.cpp:239] Iteration 1700 (7.88125 iter/s, 6.34417s/50 iters), loss = 4.90628e-06
I0713 19:03:44.095399 25233 solver.cpp:258]     Train net output #0: loss = 4.85411e-06 (* 1 = 4.85411e-06 loss)
I0713 19:03:44.095420 25233 sgd_solver.cpp:112] Iteration 1700, lr = 0.01
I0713 19:03:45.631100 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:03:50.293254 25233 solver.cpp:239] Iteration 1750 (8.06721 iter/s, 6.19793s/50 iters), loss = 3.02123e-06
I0713 19:03:50.293334 25233 solver.cpp:258]     Train net output #0: loss = 2.96907e-06 (* 1 = 2.96907e-06 loss)
I0713 19:03:50.293346 25233 sgd_solver.cpp:112] Iteration 1750, lr = 0.01
I0713 19:03:55.424360 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:03:56.438998 25233 solver.cpp:464] Snapshotting to binary proto file models/caffenet/caffenet_train_iter_1800.caffemodel
I0713 19:03:56.687574 25233 sgd_solver.cpp:284] Snapshotting solver state to binary proto file models/caffenet/caffenet_train_iter_1800.solverstate
I0713 19:03:56.818413 25233 solver.cpp:347] Iteration 1800, Testing net (#0)
I0713 19:03:58.837474 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:03:58.906560 25233 solver.cpp:414]     Test net output #0: accuracy = 1
I0713 19:03:58.906621 25233 solver.cpp:414]     Test net output #1: loss = 1.54615e-06 (* 1 = 1.54615e-06 loss)
I0713 19:03:59.054479 25233 solver.cpp:239] Iteration 1800 (5.70694 iter/s, 8.76126s/50 iters), loss = 2.33205e-06
I0713 19:03:59.062343 25233 solver.cpp:258]     Train net output #0: loss = 2.27989e-06 (* 1 = 2.27989e-06 loss)
I0713 19:03:59.062367 25233 sgd_solver.cpp:112] Iteration 1800, lr = 0.01
I0713 19:04:05.312680 25233 solver.cpp:239] Iteration 1850 (7.99954 iter/s, 6.25036s/50 iters), loss = 1.88129e-06
I0713 19:04:05.312808 25233 solver.cpp:258]     Train net output #0: loss = 1.82912e-06 (* 1 = 1.82912e-06 loss)
I0713 19:04:05.312825 25233 sgd_solver.cpp:112] Iteration 1850, lr = 0.01
I0713 19:04:07.741734 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:04:11.562352 25233 solver.cpp:239] Iteration 1900 (8.00051 iter/s, 6.2496s/50 iters), loss = 2.11598e-06
I0713 19:04:11.567482 25233 solver.cpp:258]     Train net output #0: loss = 2.06382e-06 (* 1 = 2.06382e-06 loss)
I0713 19:04:11.567505 25233 sgd_solver.cpp:112] Iteration 1900, lr = 0.01
I0713 19:04:17.620357 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:04:17.923422 25233 solver.cpp:239] Iteration 1950 (7.86654 iter/s, 6.35603s/50 iters), loss = 1.43053e-06
I0713 19:04:17.928409 25233 solver.cpp:258]     Train net output #0: loss = 1.37836e-06 (* 1 = 1.37836e-06 loss)
I0713 19:04:17.928442 25233 sgd_solver.cpp:112] Iteration 1950, lr = 0.01
I0713 19:04:24.120162 25233 solver.cpp:347] Iteration 2000, Testing net (#0)
I0713 19:04:26.087849 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:04:26.155910 25233 solver.cpp:414]     Test net output #0: accuracy = 1
I0713 19:04:26.156003 25233 solver.cpp:414]     Test net output #1: loss = 1.54543e-06 (* 1 = 1.54543e-06 loss)
I0713 19:04:26.289467 25233 solver.cpp:239] Iteration 2000 (5.98002 iter/s, 8.36118s/50 iters), loss = 3.08084e-06
I0713 19:04:26.297426 25233 solver.cpp:258]     Train net output #0: loss = 3.02868e-06 (* 1 = 3.02868e-06 loss)
I0713 19:04:26.297452 25233 sgd_solver.cpp:112] Iteration 2000, lr = 0.001
I0713 19:04:29.362994 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:04:32.549990 25233 solver.cpp:239] Iteration 2050 (7.9966 iter/s, 6.25266s/50 iters), loss = 2.58164e-06
I0713 19:04:32.550057 25233 solver.cpp:258]     Train net output #0: loss = 2.52948e-06 (* 1 = 2.52948e-06 loss)
I0713 19:04:32.550067 25233 sgd_solver.cpp:112] Iteration 2050, lr = 0.001
I0713 19:04:38.797603 25233 solver.cpp:239] Iteration 2100 (8.00303 iter/s, 6.24763s/50 iters), loss = 4.30649e-06
I0713 19:04:38.797662 25233 solver.cpp:258]     Train net output #0: loss = 4.25433e-06 (* 1 = 4.25433e-06 loss)
I0713 19:04:38.797672 25233 sgd_solver.cpp:112] Iteration 2100, lr = 0.001
I0713 19:04:39.121145 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:04:45.074614 25233 solver.cpp:239] Iteration 2150 (7.96563 iter/s, 6.27696s/50 iters), loss = 3.59122e-06
I0713 19:04:45.080636 25233 solver.cpp:258]     Train net output #0: loss = 3.53906e-06 (* 1 = 3.53906e-06 loss)
I0713 19:04:45.080667 25233 sgd_solver.cpp:112] Iteration 2150, lr = 0.001
I0713 19:04:49.010076 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:04:51.211980 25233 solver.cpp:347] Iteration 2200, Testing net (#0)
I0713 19:04:53.223760 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:04:53.317140 25233 solver.cpp:414]     Test net output #0: accuracy = 1
I0713 19:04:53.317234 25233 solver.cpp:414]     Test net output #1: loss = 1.54503e-06 (* 1 = 1.54503e-06 loss)
I0713 19:04:53.438520 25233 solver.cpp:239] Iteration 2200 (5.98228 iter/s, 8.35802s/50 iters), loss = 5.09254e-06
I0713 19:04:53.446429 25233 solver.cpp:258]     Train net output #0: loss = 5.04038e-06 (* 1 = 5.04038e-06 loss)
I0713 19:04:53.446455 25233 sgd_solver.cpp:112] Iteration 2200, lr = 0.001
I0713 19:04:59.722378 25233 solver.cpp:239] Iteration 2250 (7.96679 iter/s, 6.27605s/50 iters), loss = 2.1309e-06
I0713 19:04:59.722472 25233 solver.cpp:258]     Train net output #0: loss = 2.07874e-06 (* 1 = 2.07874e-06 loss)
I0713 19:04:59.722492 25233 sgd_solver.cpp:112] Iteration 2250, lr = 0.001
I0713 19:05:00.772050 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:05:06.023882 25233 solver.cpp:239] Iteration 2300 (7.93477 iter/s, 6.30138s/50 iters), loss = 2.55184e-06
I0713 19:05:06.024013 25233 solver.cpp:258]     Train net output #0: loss = 2.49968e-06 (* 1 = 2.49968e-06 loss)
I0713 19:05:06.024034 25233 sgd_solver.cpp:112] Iteration 2300, lr = 0.001
I0713 19:05:10.621122 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:05:12.308662 25233 solver.cpp:239] Iteration 2350 (7.95587 iter/s, 6.28467s/50 iters), loss = 5.2304e-06
I0713 19:05:12.314388 25233 solver.cpp:258]     Train net output #0: loss = 5.17824e-06 (* 1 = 5.17824e-06 loss)
I0713 19:05:12.314424 25233 sgd_solver.cpp:112] Iteration 2350, lr = 0.001
I0713 19:05:18.386602 25233 solver.cpp:347] Iteration 2400, Testing net (#0)
I0713 19:05:20.419536 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:05:20.522116 25233 solver.cpp:414]     Test net output #0: accuracy = 1
I0713 19:05:20.522168 25233 solver.cpp:414]     Test net output #1: loss = 1.54511e-06 (* 1 = 1.54511e-06 loss)
I0713 19:05:20.643342 25233 solver.cpp:239] Iteration 2400 (6.00305 iter/s, 8.3291s/50 iters), loss = 3.11809e-06
I0713 19:05:20.651504 25233 solver.cpp:258]     Train net output #0: loss = 3.06593e-06 (* 1 = 3.06593e-06 loss)
I0713 19:05:20.651546 25233 sgd_solver.cpp:112] Iteration 2400, lr = 0.001
I0713 19:05:22.522810 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:05:26.987547 25233 solver.cpp:239] Iteration 2450 (7.89123 iter/s, 6.33614s/50 iters), loss = 1.91109e-06
I0713 19:05:26.987623 25233 solver.cpp:258]     Train net output #0: loss = 1.85893e-06 (* 1 = 1.85893e-06 loss)
I0713 19:05:26.987638 25233 sgd_solver.cpp:112] Iteration 2450, lr = 0.001
I0713 19:05:32.386102 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:05:33.274022 25233 solver.cpp:239] Iteration 2500 (7.95359 iter/s, 6.28647s/50 iters), loss = 2.76791e-06
I0713 19:05:33.274096 25233 solver.cpp:258]     Train net output #0: loss = 2.71575e-06 (* 1 = 2.71575e-06 loss)
I0713 19:05:33.274111 25233 sgd_solver.cpp:112] Iteration 2500, lr = 0.001
I0713 19:05:39.527648 25233 solver.cpp:239] Iteration 2550 (7.99534 iter/s, 6.25364s/50 iters), loss = 2.61517e-06
I0713 19:05:39.527705 25233 solver.cpp:258]     Train net output #0: loss = 2.56301e-06 (* 1 = 2.56301e-06 loss)
I0713 19:05:39.527714 25233 sgd_solver.cpp:112] Iteration 2550, lr = 0.001
I0713 19:05:42.244210 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:05:45.714650 25233 solver.cpp:347] Iteration 2600, Testing net (#0)
I0713 19:05:47.677976 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:05:47.783284 25233 solver.cpp:414]     Test net output #0: accuracy = 1
I0713 19:05:47.783350 25233 solver.cpp:414]     Test net output #1: loss = 1.54519e-06 (* 1 = 1.54519e-06 loss)
I0713 19:05:47.903808 25233 solver.cpp:239] Iteration 2600 (5.96928 iter/s, 8.37622s/50 iters), loss = 5.62899e-06
I0713 19:05:47.911965 25233 solver.cpp:258]     Train net output #0: loss = 5.57683e-06 (* 1 = 5.57683e-06 loss)
I0713 19:05:47.911988 25233 sgd_solver.cpp:112] Iteration 2600, lr = 0.001
I0713 19:05:54.152590 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:05:54.224550 25233 solver.cpp:239] Iteration 2650 (7.92563 iter/s, 6.30865s/50 iters), loss = 2.96164e-06
I0713 19:05:54.224632 25233 solver.cpp:258]     Train net output #0: loss = 2.90948e-06 (* 1 = 2.90948e-06 loss)
I0713 19:05:54.224642 25233 sgd_solver.cpp:112] Iteration 2650, lr = 0.001
I0713 19:06:00.396323 25233 solver.cpp:464] Snapshotting to binary proto file models/caffenet/caffenet_train_iter_2700.caffemodel
I0713 19:06:00.653769 25233 sgd_solver.cpp:284] Snapshotting solver state to binary proto file models/caffenet/caffenet_train_iter_2700.solverstate
I0713 19:06:00.913806 25233 solver.cpp:239] Iteration 2700 (7.47466 iter/s, 6.68926s/50 iters), loss = 4.47785e-06
I0713 19:06:00.913875 25233 solver.cpp:258]     Train net output #0: loss = 4.42569e-06 (* 1 = 4.42569e-06 loss)
I0713 19:06:00.913889 25233 sgd_solver.cpp:112] Iteration 2700, lr = 0.001
I0713 19:06:04.450893 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:06:07.219156 25233 solver.cpp:239] Iteration 2750 (7.92977 iter/s, 6.30536s/50 iters), loss = 9.70848e-06
I0713 19:06:07.219235 25233 solver.cpp:258]     Train net output #0: loss = 9.65632e-06 (* 1 = 9.65632e-06 loss)
I0713 19:06:07.219249 25233 sgd_solver.cpp:112] Iteration 2750, lr = 0.001
I0713 19:06:13.341132 25233 solver.cpp:347] Iteration 2800, Testing net (#0)
I0713 19:06:15.269845 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:06:15.363543 25233 solver.cpp:414]     Test net output #0: accuracy = 1
I0713 19:06:15.363601 25233 solver.cpp:414]     Test net output #1: loss = 1.54519e-06 (* 1 = 1.54519e-06 loss)
I0713 19:06:15.487211 25233 solver.cpp:239] Iteration 2800 (6.04735 iter/s, 8.26809s/50 iters), loss = 8.45676e-06
I0713 19:06:15.495369 25233 solver.cpp:258]     Train net output #0: loss = 8.4046e-06 (* 1 = 8.4046e-06 loss)
I0713 19:06:15.495399 25233 sgd_solver.cpp:112] Iteration 2800, lr = 0.001
I0713 19:06:16.214964 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:06:21.805007 25233 solver.cpp:239] Iteration 2850 (7.92429 iter/s, 6.30971s/50 iters), loss = 8.24429e-06
I0713 19:06:21.805114 25233 solver.cpp:258]     Train net output #0: loss = 8.19213e-06 (* 1 = 8.19213e-06 loss)
I0713 19:06:21.805131 25233 sgd_solver.cpp:112] Iteration 2850, lr = 0.001
I0713 19:06:25.996515 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:06:28.076889 25233 solver.cpp:239] Iteration 2900 (7.97211 iter/s, 6.27187s/50 iters), loss = 2.27244e-06
I0713 19:06:28.076953 25233 solver.cpp:258]     Train net output #0: loss = 2.22028e-06 (* 1 = 2.22028e-06 loss)
I0713 19:06:28.076963 25233 sgd_solver.cpp:112] Iteration 2900, lr = 0.001
I0713 19:06:34.359519 25233 solver.cpp:239] Iteration 2950 (7.95842 iter/s, 6.28266s/50 iters), loss = 2.9579e-06
I0713 19:06:34.359581 25233 solver.cpp:258]     Train net output #0: loss = 2.90574e-06 (* 1 = 2.90574e-06 loss)
I0713 19:06:34.359591 25233 sgd_solver.cpp:112] Iteration 2950, lr = 0.001
I0713 19:06:35.840049 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:06:40.516593 25233 solver.cpp:347] Iteration 3000, Testing net (#0)
I0713 19:06:42.478798 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:06:42.571708 25233 solver.cpp:414]     Test net output #0: accuracy = 1
I0713 19:06:42.571761 25233 solver.cpp:414]     Test net output #1: loss = 1.54527e-06 (* 1 = 1.54527e-06 loss)
I0713 19:06:42.711865 25233 solver.cpp:239] Iteration 3000 (5.9863 iter/s, 8.35241s/50 iters), loss = 5.1484e-06
I0713 19:06:42.711921 25233 solver.cpp:258]     Train net output #0: loss = 5.09624e-06 (* 1 = 5.09624e-06 loss)
I0713 19:06:42.711935 25233 sgd_solver.cpp:112] Iteration 3000, lr = 0.0001
I0713 19:06:47.667342 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:06:49.005708 25233 solver.cpp:239] Iteration 3050 (7.94423 iter/s, 6.29388s/50 iters), loss = 2.89085e-06
I0713 19:06:49.005782 25233 solver.cpp:258]     Train net output #0: loss = 2.83869e-06 (* 1 = 2.83869e-06 loss)
I0713 19:06:49.005792 25233 sgd_solver.cpp:112] Iteration 3050, lr = 0.0001
I0713 19:06:55.349761 25233 solver.cpp:239] Iteration 3100 (7.88142 iter/s, 6.34404s/50 iters), loss = 2.43635e-06
I0713 19:06:55.349854 25233 solver.cpp:258]     Train net output #0: loss = 2.38419e-06 (* 1 = 2.38419e-06 loss)
I0713 19:06:55.349870 25233 sgd_solver.cpp:112] Iteration 3100, lr = 0.0001
I0713 19:06:57.550999 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:07:01.645730 25233 solver.cpp:239] Iteration 3150 (7.94161 iter/s, 6.29596s/50 iters), loss = 7.8867e-06
I0713 19:07:01.645797 25233 solver.cpp:258]     Train net output #0: loss = 7.83454e-06 (* 1 = 7.83454e-06 loss)
I0713 19:07:01.645808 25233 sgd_solver.cpp:112] Iteration 3150, lr = 0.0001
I0713 19:07:07.351876 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:07:07.723630 25233 solver.cpp:347] Iteration 3200, Testing net (#0)
I0713 19:07:09.803598 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:07:09.897012 25233 solver.cpp:414]     Test net output #0: accuracy = 1
I0713 19:07:09.897079 25233 solver.cpp:414]     Test net output #1: loss = 1.54503e-06 (* 1 = 1.54503e-06 loss)
I0713 19:07:10.039523 25233 solver.cpp:239] Iteration 3200 (5.95674 iter/s, 8.39385s/50 iters), loss = 6.26229e-06
I0713 19:07:10.047245 25233 solver.cpp:258]     Train net output #0: loss = 6.21013e-06 (* 1 = 6.21013e-06 loss)
I0713 19:07:10.047287 25233 sgd_solver.cpp:112] Iteration 3200, lr = 0.0001
I0713 19:07:16.329340 25233 solver.cpp:239] Iteration 3250 (7.95899 iter/s, 6.2822s/50 iters), loss = 3.66948e-06
I0713 19:07:16.329408 25233 solver.cpp:258]     Train net output #0: loss = 3.61732e-06 (* 1 = 3.61732e-06 loss)
I0713 19:07:16.329423 25233 sgd_solver.cpp:112] Iteration 3250, lr = 0.0001
I0713 19:07:19.377715 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:07:22.671066 25233 solver.cpp:239] Iteration 3300 (7.8843 iter/s, 6.34172s/50 iters), loss = 1.87011e-06
I0713 19:07:22.671169 25233 solver.cpp:258]     Train net output #0: loss = 1.81795e-06 (* 1 = 1.81795e-06 loss)
I0713 19:07:22.671191 25233 sgd_solver.cpp:112] Iteration 3300, lr = 0.0001
I0713 19:07:28.978490 25233 solver.cpp:239] Iteration 3350 (7.9272 iter/s, 6.3074s/50 iters), loss = 7.73023e-06
I0713 19:07:28.978731 25233 solver.cpp:258]     Train net output #0: loss = 7.67807e-06 (* 1 = 7.67807e-06 loss)
I0713 19:07:28.978749 25233 sgd_solver.cpp:112] Iteration 3350, lr = 0.0001
I0713 19:07:29.148514 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:07:35.134418 25233 solver.cpp:347] Iteration 3400, Testing net (#0)
I0713 19:07:37.164295 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:07:37.281978 25233 solver.cpp:414]     Test net output #0: accuracy = 1
I0713 19:07:37.282048 25233 solver.cpp:414]     Test net output #1: loss = 1.54472e-06 (* 1 = 1.54472e-06 loss)
I0713 19:07:37.418536 25233 solver.cpp:239] Iteration 3400 (5.92422 iter/s, 8.43993s/50 iters), loss = 2.70458e-06
I0713 19:07:37.418612 25233 solver.cpp:258]     Train net output #0: loss = 2.65242e-06 (* 1 = 2.65242e-06 loss)
I0713 19:07:37.418628 25233 sgd_solver.cpp:112] Iteration 3400, lr = 0.0001
I0713 19:07:41.175698 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:07:43.710397 25233 solver.cpp:239] Iteration 3450 (7.94679 iter/s, 6.29185s/50 iters), loss = 2.64871e-06
I0713 19:07:43.715638 25233 solver.cpp:258]     Train net output #0: loss = 2.59655e-06 (* 1 = 2.59655e-06 loss)
I0713 19:07:43.715662 25233 sgd_solver.cpp:112] Iteration 3450, lr = 0.0001
I0713 19:07:50.036897 25233 solver.cpp:239] Iteration 3500 (7.90974 iter/s, 6.32132s/50 iters), loss = 2.07127e-06
I0713 19:07:50.037006 25233 solver.cpp:258]     Train net output #0: loss = 2.01911e-06 (* 1 = 2.01911e-06 loss)
I0713 19:07:50.037025 25233 sgd_solver.cpp:112] Iteration 3500, lr = 0.0001
I0713 19:07:51.029036 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:07:56.326126 25233 solver.cpp:239] Iteration 3550 (7.95014 iter/s, 6.2892s/50 iters), loss = 2.9132e-06
I0713 19:07:56.326236 25233 solver.cpp:258]     Train net output #0: loss = 2.86104e-06 (* 1 = 2.86104e-06 loss)
I0713 19:07:56.326253 25233 sgd_solver.cpp:112] Iteration 3550, lr = 0.0001
I0713 19:08:00.927664 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:08:02.454705 25233 solver.cpp:464] Snapshotting to binary proto file models/caffenet/caffenet_train_iter_3600.caffemodel
I0713 19:08:02.686941 25233 sgd_solver.cpp:284] Snapshotting solver state to binary proto file models/caffenet/caffenet_train_iter_3600.solverstate
I0713 19:08:02.816390 25233 solver.cpp:347] Iteration 3600, Testing net (#0)
I0713 19:08:04.773635 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:08:04.862154 25233 solver.cpp:414]     Test net output #0: accuracy = 1
I0713 19:08:04.862215 25233 solver.cpp:414]     Test net output #1: loss = 1.54456e-06 (* 1 = 1.54456e-06 loss)
I0713 19:08:05.003023 25233 solver.cpp:239] Iteration 3600 (5.76242 iter/s, 8.67691s/50 iters), loss = 3.15535e-06
I0713 19:08:05.010905 25233 solver.cpp:258]     Train net output #0: loss = 3.10319e-06 (* 1 = 3.10319e-06 loss)
I0713 19:08:05.010932 25233 sgd_solver.cpp:112] Iteration 3600, lr = 0.0001
I0713 19:08:11.304237 25233 solver.cpp:239] Iteration 3650 (7.94484 iter/s, 6.29339s/50 iters), loss = 3.94885e-06
I0713 19:08:11.304339 25233 solver.cpp:258]     Train net output #0: loss = 3.89669e-06 (* 1 = 3.89669e-06 loss)
I0713 19:08:11.304358 25233 sgd_solver.cpp:112] Iteration 3650, lr = 0.0001
I0713 19:08:13.048609 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:08:17.627454 25233 solver.cpp:239] Iteration 3700 (7.90743 iter/s, 6.32316s/50 iters), loss = 3.86316e-06
I0713 19:08:17.627568 25233 solver.cpp:258]     Train net output #0: loss = 3.811e-06 (* 1 = 3.811e-06 loss)
I0713 19:08:17.627589 25233 sgd_solver.cpp:112] Iteration 3700, lr = 0.0001
I0713 19:08:22.889989 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:08:23.950317 25233 solver.cpp:239] Iteration 3750 (7.90787 iter/s, 6.32281s/50 iters), loss = 5.60305e-06
I0713 19:08:23.950449 25233 solver.cpp:258]     Train net output #0: loss = 5.55089e-06 (* 1 = 5.55089e-06 loss)
I0713 19:08:23.950470 25233 sgd_solver.cpp:112] Iteration 3750, lr = 0.0001
I0713 19:08:29.934129 25233 solver.cpp:347] Iteration 3800, Testing net (#0)
I0713 19:08:31.972302 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:08:32.071432 25233 solver.cpp:414]     Test net output #0: accuracy = 1
I0713 19:08:32.071557 25233 solver.cpp:414]     Test net output #1: loss = 1.54432e-06 (* 1 = 1.54432e-06 loss)
I0713 19:08:32.208539 25233 solver.cpp:239] Iteration 3800 (6.05455 iter/s, 8.25825s/50 iters), loss = 3.39377e-06
I0713 19:08:32.208602 25233 solver.cpp:258]     Train net output #0: loss = 3.34161e-06 (* 1 = 3.34161e-06 loss)
I0713 19:08:32.208616 25233 sgd_solver.cpp:112] Iteration 3800, lr = 0.0001
I0713 19:08:34.693193 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:08:38.547785 25233 solver.cpp:239] Iteration 3850 (7.88737 iter/s, 6.33925s/50 iters), loss = 5.00686e-06
I0713 19:08:38.547863 25233 solver.cpp:258]     Train net output #0: loss = 4.9547e-06 (* 1 = 4.9547e-06 loss)
I0713 19:08:38.547876 25233 sgd_solver.cpp:112] Iteration 3850, lr = 0.0001
I0713 19:08:44.623397 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:08:44.863857 25233 solver.cpp:239] Iteration 3900 (7.9163 iter/s, 6.31608s/50 iters), loss = 3.09947e-06
I0713 19:08:44.863924 25233 solver.cpp:258]     Train net output #0: loss = 3.04731e-06 (* 1 = 3.04731e-06 loss)
I0713 19:08:44.863932 25233 sgd_solver.cpp:112] Iteration 3900, lr = 0.0001
I0713 19:08:51.181208 25233 solver.cpp:239] Iteration 3950 (7.91536 iter/s, 6.31683s/50 iters), loss = 6.27352e-06
I0713 19:08:51.181324 25233 solver.cpp:258]     Train net output #0: loss = 6.22137e-06 (* 1 = 6.22137e-06 loss)
I0713 19:08:51.181347 25233 sgd_solver.cpp:112] Iteration 3950, lr = 0.0001
I0713 19:08:54.428500 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:08:57.314728 25233 solver.cpp:347] Iteration 4000, Testing net (#0)
I0713 19:08:59.372879 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:08:59.467020 25233 solver.cpp:414]     Test net output #0: accuracy = 1
I0713 19:08:59.467092 25233 solver.cpp:414]     Test net output #1: loss = 1.54392e-06 (* 1 = 1.54392e-06 loss)
I0713 19:08:59.599045 25233 solver.cpp:239] Iteration 4000 (5.93978 iter/s, 8.41782s/50 iters), loss = 2.87594e-06
I0713 19:08:59.599128 25233 solver.cpp:258]     Train net output #0: loss = 2.82378e-06 (* 1 = 2.82378e-06 loss)
I0713 19:08:59.599143 25233 sgd_solver.cpp:112] Iteration 4000, lr = 1e-05
I0713 19:09:05.920536 25233 solver.cpp:239] Iteration 4050 (7.90952 iter/s, 6.32149s/50 iters), loss = 4.67157e-06
I0713 19:09:05.920789 25233 solver.cpp:258]     Train net output #0: loss = 4.61941e-06 (* 1 = 4.61941e-06 loss)
I0713 19:09:05.920805 25233 sgd_solver.cpp:112] Iteration 4050, lr = 1e-05
I0713 19:09:06.382411 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:09:12.243244 25233 solver.cpp:239] Iteration 4100 (7.90824 iter/s, 6.32252s/50 iters), loss = 1.66521e-06
I0713 19:09:12.243346 25233 solver.cpp:258]     Train net output #0: loss = 1.61306e-06 (* 1 = 1.61306e-06 loss)
I0713 19:09:12.243366 25233 sgd_solver.cpp:112] Iteration 4100, lr = 1e-05
I0713 19:09:16.292230 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:09:18.521572 25233 solver.cpp:239] Iteration 4150 (7.96392 iter/s, 6.27831s/50 iters), loss = 3.64335e-06
I0713 19:09:18.521625 25233 solver.cpp:258]     Train net output #0: loss = 3.5912e-06 (* 1 = 3.5912e-06 loss)
I0713 19:09:18.521636 25233 sgd_solver.cpp:112] Iteration 4150, lr = 1e-05
I0713 19:09:24.627180 25233 solver.cpp:347] Iteration 4200, Testing net (#0)
I0713 19:09:26.697264 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:09:26.798404 25233 solver.cpp:414]     Test net output #0: accuracy = 1
I0713 19:09:26.798470 25233 solver.cpp:414]     Test net output #1: loss = 1.54392e-06 (* 1 = 1.54392e-06 loss)
I0713 19:09:26.934154 25233 solver.cpp:239] Iteration 4200 (5.94343 iter/s, 8.41265s/50 iters), loss = 4.13141e-06
I0713 19:09:26.934218 25233 solver.cpp:258]     Train net output #0: loss = 4.07925e-06 (* 1 = 4.07925e-06 loss)
I0713 19:09:26.934236 25233 sgd_solver.cpp:112] Iteration 4200, lr = 1e-05
I0713 19:09:28.212811 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:09:33.176348 25233 solver.cpp:239] Iteration 4250 (8.00997 iter/s, 6.24222s/50 iters), loss = 3.94512e-06
I0713 19:09:33.176414 25233 solver.cpp:258]     Train net output #0: loss = 3.89296e-06 (* 1 = 3.89296e-06 loss)
I0713 19:09:33.176424 25233 sgd_solver.cpp:112] Iteration 4250, lr = 1e-05
I0713 19:09:38.056581 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:09:39.496501 25233 solver.cpp:239] Iteration 4300 (7.91118 iter/s, 6.32017s/50 iters), loss = 2.57419e-06
I0713 19:09:39.501396 25233 solver.cpp:258]     Train net output #0: loss = 2.52203e-06 (* 1 = 2.52203e-06 loss)
I0713 19:09:39.501427 25233 sgd_solver.cpp:112] Iteration 4300, lr = 1e-05
I0713 19:09:45.808763 25233 solver.cpp:239] Iteration 4350 (7.9271 iter/s, 6.30748s/50 iters), loss = 3.23731e-06
I0713 19:09:45.808841 25233 solver.cpp:258]     Train net output #0: loss = 3.18515e-06 (* 1 = 3.18515e-06 loss)
I0713 19:09:45.808856 25233 sgd_solver.cpp:112] Iteration 4350, lr = 1e-05
I0713 19:09:47.805851 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:09:51.966646 25233 solver.cpp:347] Iteration 4400, Testing net (#0)
I0713 19:09:54.052245 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:09:54.134100 25233 solver.cpp:414]     Test net output #0: accuracy = 1
I0713 19:09:54.134181 25233 solver.cpp:414]     Test net output #1: loss = 1.54392e-06 (* 1 = 1.54392e-06 loss)
I0713 19:09:54.278578 25233 solver.cpp:239] Iteration 4400 (5.90328 iter/s, 8.46986s/50 iters), loss = 9.25019e-06
I0713 19:09:54.286698 25233 solver.cpp:258]     Train net output #0: loss = 9.19803e-06 (* 1 = 9.19803e-06 loss)
I0713 19:09:54.286723 25233 sgd_solver.cpp:112] Iteration 4400, lr = 1e-05
I0713 19:09:59.954051 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:10:00.762678 25233 solver.cpp:239] Iteration 4450 (7.72078 iter/s, 6.47603s/50 iters), loss = 3.49061e-06
I0713 19:10:00.762800 25233 solver.cpp:258]     Train net output #0: loss = 3.43846e-06 (* 1 = 3.43846e-06 loss)
I0713 19:10:00.762821 25233 sgd_solver.cpp:112] Iteration 4450, lr = 1e-05
I0713 19:10:07.153213 25233 solver.cpp:464] Snapshotting to binary proto file models/caffenet/caffenet_train_iter_4500.caffemodel
I0713 19:10:07.406003 25233 sgd_solver.cpp:284] Snapshotting solver state to binary proto file models/caffenet/caffenet_train_iter_4500.solverstate
I0713 19:10:07.653218 25233 solver.cpp:239] Iteration 4500 (7.25635 iter/s, 6.89051s/50 iters), loss = 2.53321e-06
I0713 19:10:07.653298 25233 solver.cpp:258]     Train net output #0: loss = 2.48105e-06 (* 1 = 2.48105e-06 loss)
I0713 19:10:07.653316 25233 sgd_solver.cpp:112] Iteration 4500, lr = 1e-05
I0713 19:10:10.604985 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:10:14.384745 25233 solver.cpp:239] Iteration 4550 (7.42774 iter/s, 6.73153s/50 iters), loss = 3.02499e-06
I0713 19:10:14.384835 25233 solver.cpp:258]     Train net output #0: loss = 2.97284e-06 (* 1 = 2.97284e-06 loss)
I0713 19:10:14.384853 25233 sgd_solver.cpp:112] Iteration 4550, lr = 1e-05
I0713 19:10:20.823199 25233 solver.cpp:347] Iteration 4600, Testing net (#0)
I0713 19:10:22.889084 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:10:22.986366 25233 solver.cpp:414]     Test net output #0: accuracy = 1
I0713 19:10:22.986423 25233 solver.cpp:414]     Test net output #1: loss = 1.54392e-06 (* 1 = 1.54392e-06 loss)
I0713 19:10:23.054741 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:10:23.124090 25233 solver.cpp:239] Iteration 4600 (5.72123 iter/s, 8.73938s/50 iters), loss = 3.24847e-06
I0713 19:10:23.124161 25233 solver.cpp:258]     Train net output #0: loss = 3.19632e-06 (* 1 = 3.19632e-06 loss)
I0713 19:10:23.124179 25233 sgd_solver.cpp:112] Iteration 4600, lr = 1e-05
I0713 19:10:29.479079 25233 solver.cpp:239] Iteration 4650 (7.86787 iter/s, 6.35496s/50 iters), loss = 2.30596e-06
I0713 19:10:29.479184 25233 solver.cpp:258]     Train net output #0: loss = 2.25381e-06 (* 1 = 2.25381e-06 loss)
I0713 19:10:29.479202 25233 sgd_solver.cpp:112] Iteration 4650, lr = 1e-05
I0713 19:10:32.984562 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:10:35.800278 25233 solver.cpp:239] Iteration 4700 (7.90995 iter/s, 6.32115s/50 iters), loss = 2.04892e-06
I0713 19:10:35.800361 25233 solver.cpp:258]     Train net output #0: loss = 1.99677e-06 (* 1 = 1.99677e-06 loss)
I0713 19:10:35.800376 25233 sgd_solver.cpp:112] Iteration 4700, lr = 1e-05
I0713 19:10:42.100327 25233 solver.cpp:239] Iteration 4750 (7.93649 iter/s, 6.30001s/50 iters), loss = 4.81686e-06
I0713 19:10:42.100591 25233 solver.cpp:258]     Train net output #0: loss = 4.76471e-06 (* 1 = 4.76471e-06 loss)
I0713 19:10:42.100615 25233 sgd_solver.cpp:112] Iteration 4750, lr = 1e-05
I0713 19:10:42.765023 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:10:48.079324 25233 solver.cpp:347] Iteration 4800, Testing net (#0)
I0713 19:10:50.037446 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:10:50.130904 25233 solver.cpp:414]     Test net output #0: accuracy = 1
I0713 19:10:50.130971 25233 solver.cpp:414]     Test net output #1: loss = 1.54392e-06 (* 1 = 1.54392e-06 loss)
I0713 19:10:50.271144 25233 solver.cpp:239] Iteration 4800 (6.11943 iter/s, 8.1707s/50 iters), loss = 6.8062e-06
I0713 19:10:50.278935 25233 solver.cpp:258]     Train net output #0: loss = 6.75405e-06 (* 1 = 6.75405e-06 loss)
I0713 19:10:50.278961 25233 sgd_solver.cpp:112] Iteration 4800, lr = 1e-05
I0713 19:10:54.566741 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:10:56.556604 25233 solver.cpp:239] Iteration 4850 (7.96464 iter/s, 6.27775s/50 iters), loss = 3.59866e-06
I0713 19:10:56.556708 25233 solver.cpp:258]     Train net output #0: loss = 3.54651e-06 (* 1 = 3.54651e-06 loss)
I0713 19:10:56.556723 25233 sgd_solver.cpp:112] Iteration 4850, lr = 1e-05
I0713 19:11:02.816529 25233 solver.cpp:239] Iteration 4900 (7.98731 iter/s, 6.25993s/50 iters), loss = 2.81633e-06
I0713 19:11:02.816596 25233 solver.cpp:258]     Train net output #0: loss = 2.76418e-06 (* 1 = 2.76418e-06 loss)
I0713 19:11:02.816606 25233 sgd_solver.cpp:112] Iteration 4900, lr = 1e-05
I0713 19:11:04.309733 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:11:09.101851 25233 solver.cpp:239] Iteration 4950 (7.95507 iter/s, 6.2853s/50 iters), loss = 6.68338e-06
I0713 19:11:09.101971 25233 solver.cpp:258]     Train net output #0: loss = 6.63123e-06 (* 1 = 6.63123e-06 loss)
I0713 19:11:09.101992 25233 sgd_solver.cpp:112] Iteration 4950, lr = 1e-05
I0713 19:11:14.014905 25238 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:11:15.182945 25233 solver.cpp:464] Snapshotting to binary proto file models/caffenet/caffenet_train_iter_5000.caffemodel
I0713 19:11:15.459030 25233 sgd_solver.cpp:284] Snapshotting solver state to binary proto file models/caffenet/caffenet_train_iter_5000.solverstate
I0713 19:11:15.636471 25233 solver.cpp:327] Iteration 5000, loss = 5.34214e-06
I0713 19:11:15.636584 25233 solver.cpp:347] Iteration 5000, Testing net (#0)
I0713 19:11:17.515761 25239 data_layer.cpp:73] Restarting data prefetching from start.
I0713 19:11:17.624143 25233 solver.cpp:414]     Test net output #0: accuracy = 1
I0713 19:11:17.624203 25233 solver.cpp:414]     Test net output #1: loss = 1.54392e-06 (* 1 = 1.54392e-06 loss)
I0713 19:11:17.624212 25233 solver.cpp:332] Optimization Done.
I0713 19:11:17.624217 25233 caffe.cpp:250] Optimization Done.
